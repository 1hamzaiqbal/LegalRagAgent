# --- Active provider (set LLM_PROVIDER to switch) ---
# Run `uv run python llm_config.py` to see all 19 providers with rate limits.
LLM_PROVIDER=gemma

# --- Google AI Studio (recommended: gemma-3-27b-it, 14.4K RPD free) ---
GOOGLE_API_KEY=your-google-ai-studio-key-here

# --- Groq (llama-3.3-70b, 1K RPD free) ---
# GROQ_API_KEY=gsk_your-groq-key-here

# --- OpenRouter (free tier, weekly token limits) ---
# OPENROUTER_API_KEY=sk-or-v1-your-openrouter-key-here

# --- Cerebras (llama-3.3-70b, 14K RPD free) ---
# CEREBRAS_API_KEY=csk-your-cerebras-key-here

# --- Ollama (local, no key needed) ---
# No API key required. Set LLM_PROVIDER=ollama.

# --- Injection check (set to 1 to skip during eval/testing, saves 1 LLM call) ---
# SKIP_INJECTION_CHECK=0

# --- Eval confidence threshold (default 0.70, calibrated for gte-large-en-v1.5) ---
# EVAL_CONFIDENCE_THRESHOLD=0.70

# --- Embedding model (default: Alibaba-NLP/gte-large-en-v1.5) ---
# EMBEDDING_MODEL=Alibaba-NLP/gte-large-en-v1.5

# --- Legacy fallback (used if LLM_PROVIDER is not set) ---
# LLM_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai/
# LLM_API_KEY=your-key-here
# LLM_MODEL=gemma-3-27b-it
