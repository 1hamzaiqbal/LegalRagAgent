# --- Cerebras (recommended, 14K requests/day, 1M tokens/day) ---
LLM_BASE_URL=https://api.cerebras.ai/v1
LLM_API_KEY=YOUR_CEREBRAS_KEY_HERE
LLM_MODEL=llama-3.3-70b

# --- Google AI Studio (20 RPD for Gemini 2.5 Flash, good for single queries) ---
# LLM_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai/
# LLM_API_KEY=YOUR_GOOGLE_AI_STUDIO_KEY_HERE
# LLM_MODEL=gemini-2.5-flash

# --- Groq (free tier, 100K tokens/day, 1K requests/day) ---
# LLM_BASE_URL=https://api.groq.com/openai/v1
# LLM_API_KEY=gsk_YOUR_GROQ_KEY_HERE
# LLM_MODEL=llama-3.3-70b-versatile

# --- Ollama (local, no key needed) ---
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_API_KEY=ollama
# LLM_MODEL=llama3

# --- OpenAI ---
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_API_KEY=sk-YOUR_OPENAI_KEY_HERE
# LLM_MODEL=gpt-4o-mini

# --- DeepSeek (prefix caching reported automatically) ---
# LLM_BASE_URL=https://api.deepseek.com/v1
# LLM_API_KEY=sk-YOUR_DEEPSEEK_KEY_HERE
# LLM_MODEL=deepseek-chat

# --- vLLM (local, prefix caching with --enable-prefix-caching) ---
# LLM_BASE_URL=http://localhost:8000/v1
# LLM_API_KEY=unused
# LLM_MODEL=meta-llama/Llama-3.3-70B-Instruct
