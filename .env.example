# --- Groq (free tier, default) ---
LLM_BASE_URL=https://api.groq.com/openai/v1
LLM_API_KEY=gsk_YOUR_GROQ_KEY_HERE
LLM_MODEL=llama-3.3-70b-versatile

# --- Ollama (local, no key needed) ---
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_API_KEY=ollama
# LLM_MODEL=llama3

# --- OpenAI ---
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_API_KEY=sk-YOUR_OPENAI_KEY_HERE
# LLM_MODEL=gpt-4o-mini

# --- DeepSeek (prefix caching reported automatically) ---
# LLM_BASE_URL=https://api.deepseek.com/v1
# LLM_API_KEY=sk-YOUR_DEEPSEEK_KEY_HERE
# LLM_MODEL=deepseek-chat

# --- vLLM (local, prefix caching with --enable-prefix-caching) ---
# LLM_BASE_URL=http://localhost:8000/v1
# LLM_API_KEY=unused
# LLM_MODEL=meta-llama/Llama-3.3-70B-Instruct
